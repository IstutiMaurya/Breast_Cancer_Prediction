# -*- coding: utf-8 -*-
"""Breast Cancer Prediction Using ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nA102M8fNQZoboJx3w_RaoPuIwtC5OJj
"""

import pandas as pd
import numpy as np
import keras as tf

data=pd.read_csv("/content/breast_cancer.csv")
data.head()

data['diagnosis'].value_counts()

data.info()

#deleting the data
data = data.drop(['Unnamed: 32','id'],axis=1)
data.head()

#Check Problem for Multicolinearity
data.corr()
#radius vs perimeter_mean, area_mean, concave points_mean,radius_worst, perimeter_worst, area_worst
cols=["perimeter_mean","area_mean", "concave points_mean","radius_worst", "perimeter_worst", "area_worst"]
data= data.drop(cols,axis=1)
data.head()

data.corr()
#texture_mean vs texture_worst,
#smoothness_mean vs smoothness_worst
#compactness_mean vs concavity_mean, concavity_worst, concave point_worst, compactness_worst
#concavity_mean vs compactness_mean, concavity_worst, concave points_worst

cols1=["smoothness_worst", "concavity_mean","texture_worst", "concavity_worst", "concave points_worst", "compactness_worst"]
data=data.drop(cols1,axis=1)

#radius_se vs perimeter_se, area_se
#perimeter_se vs radius_se, area_se
cols2=["perimeter_se", "area_se"]
data=data.drop(cols2,axis=1)

data.corr()

#compactness_se	 vs concavity_se,fractal_dimension_se
cols=["concavity_se","fractal_dimension_se"]
data=data.drop(cols,axis=1)
data.corr()

data.describe()

data.head()

#divide data into features and targets
x = data.iloc[:,1:]
y = data.iloc[:,0]

#normalization/scaling
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
x = ss.fit_transform(x)
pd.DataFrame(x).describe()

## split data into train and test
from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=0.80,random_state=1)

xtest

y.value_counts()

ytrain.value_counts()

x.shape

## Build the model
model=tf.models.Sequential() ## an empty model
## add the layers
#no of features = no of neurons
model.add(tf.layers.Dense(16,input_dim=14,activation="relu"))  #input and one hidden layer
model.add(tf.layers.Dense(32,activation='relu'))   #2nd hidden layer
model.add(tf.layers.Dense(1,activation="sigmoid"))  #output layer
#if you take 1 as first parameter then it will give single output (either B or M) if 2 then it will give probability.
model.compile(loss="binary_crossentropy",optimizer='adam', metrics=["accuracy"])
# binary_crossentropy , sparse_categorical_crossentropy

#label Encoding
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
ytrain=le.fit_transform(ytrain)
ytest= le.fit_transform(ytest)

## Train the model
model.fit(xtrain,ytrain,epochs=500) #total for testing were 455 and 16 were given by us so 455/16=14.21 == 15

## Testing (Evaluation of model/ Prediction)
ypred= model.predict(xtest)
ypred =ypred.round()
ypred

ytest

model.evaluate(xtest,ytest)

#Overfitting and Underfitting
## training accuracy <<< testing accuracy (overfitting otherwise underfitting)

#testing new data
model.predict([[1,2,3,4,5,6,7,8,9,0,1,2,3,4]])

# Save the model - for future use
model.save("cancer.h5")

mymodel= tf.models.load_model("/content/cancer.h5")
mymodel.predict([[1,2,3,4,5,6,7,8,9,0,1,2,3,4]])

## Confusion Matrix
from sklearn.metrics import confusion_matrix
cm= confusion_matrix(ytest,ypred)
cm

cm.diagonal()

accuracy=cm.diagonal().sum() / cm.sum()
accuracy

#OR
from sklearn.metrics import accuracy_score
a= accuracy_score(ytest,ypred)
a

